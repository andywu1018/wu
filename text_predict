from ttexr import  tfidf_mat
from ttexr import filewordProcess
from sklearn.feature_selection import SelectKBest,chi2
import numpy as np
import pandas as pd
import pickle
import  codecs
from sklearn.externals import joblib


def tfidf_mat_pre(pre_text):
    words_list_pre = words_list
    filename_list_pre = filename_list
    category_list_pre = category_list
    pre_text = filewordProcess(pre_text)
    words_list_pre.append(pre_text)
    pre_file_name = '预测样本.txt'
    filename_list_pre.append(pre_file_name)
    pre_category_name = 'Unknown'
    category_list_pre.append(pre_category_name)
    tfidf_df_1_pre,df_columns_pre = tfidf_mat(words_list_pre,filename_list_pre,category_list_pre)
    tfidf_df_v = tfidf_df_1_pre.iloc[-1:]
    print(tfidf_df_v, df_columns_pre)
    ch2 = SelectKBest(chi2, k=10000)
    nolabel_feature_pre = [x for x in tfidf_df_v.columns if x not in ['label']]
    miss_feature = [l for l in nolabel_feature if l not in nolabel_feature_pre]
    print('丢失特征：%s >>>>>丢失个数:%s'% (miss_feature,len(miss_feature)))
    aa = {'预测样本.txt':np.zeros(len(miss_feature))}
    tfidf_df_v = tfidf_df_v.join(pd.DataFrame(aa.values(),columns=miss_feature,index=aa.keys()))
    for i in range(len(nolabel_feature_pre)):
        if nolabel_feature_pre[i] in nolabel_feature == False:
            tfidf_df_v = tfidf_df_v.drop(nolabel_feature_pre[i])
        else:
            tfidf_df_v = tfidf_df_v
    ch2_sx_np = ch2.fit_transform(tfidf_df_v[nolabel_feature_pre], tfidf_df_v['label'])
    return ch2_sx_np

def top3(p):
    top_index=np.zeros(3)
    top_prob=np.zeros(3)
    top3_list = []
    for i in range(3):
        top_index[i] = p.argsort()[-i-1]
    top_index = top_index.astype(int)
    for j in range(3):
        top_prob[j] = p[top_index[j]]
#    top3_list.append(top_index)
#    top3_list.append(top_prob)
    return top_index,top_prob


if __name__ in '__main__':
    f1 = open('D:\pickle\wordlist.txt', 'rb')
    words_list = pickle.load(f1)
    f1.close()
    f2 = open('D:\pickle\\filenamelist.txt', 'rb')
    filename_list = pickle.load(f2)
    f2.close()
    f3 = open('D:\pickle\categorylist.txt', 'rb')
    category_list = pickle.load(f3)
    f3.close()
    f4 = open('D:\pickle\\feature.txt', 'rb')
    nolabel_feature = pickle.load(f4)
    f4.close()
    pre_text = codecs.open('D:\文本分类\\新能源.txt', 'r', encoding='utf-8')
    pre_text = pre_text.read()
    category_list_v = np.unique(category_list)
    print('----------------------->开始测试<------------------------')
    print(category_list_v)
    ch2_sx_np = tfidf_mat_pre(pre_text)
    clf = joblib.load("D:\文本分类\\train_model.m")
    p = clf.predict_proba(ch2_sx_np).flatten()
    #print(p)
    top_index ,top_prob = top3(p)
    #print(top_index,top_prob)
    first = top_prob[0]
    second = top_prob[1]
    third = top_prob[2]
    if first < 0.1:
        classifier = '无法判别'
    else:
        if first/second >=2:
            classifier = '%s>>概率: %.3f'%(category_list_v[top_index[0]],top_prob[0])
        else:
            if first/third >=2:
                classifier = '%s>>概率: %.3f,%s>>概率: %.3f'%(category_list_v[top_index[0]],top_prob[0],category_list_v[top_index[1]],top_prob[1])
            else:
                classifier = '%s>>概率: %.3f,%s>>概率: %.3f,%s>>概率: %.3f'%(category_list_v[top_index[0]],top_prob[0],category_list_v[top_index[1]],top_prob[1],category_list_v[top_index[2]],top_prob[2])
    print(classifier)
